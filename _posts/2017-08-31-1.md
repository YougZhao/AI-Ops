---
layout:         post
title:          循环神经网络(Recurrent Neural Network)
subtitle:       
card-image:     /assets/images/2017-08-31-1_0.png
author:         Yang ZHAO
date:           2017-08-31 01:00:00
tags:           机器学习
post-card-type: image
---

在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。例如，要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。RNNs之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。

下图便是一个典型的RNNs：

![pic](/assets/images/2017-08-31-1_1.png)

>循环神经网络的适用性已经被在实践中证明对自然语言处理是非常成功的。如词向量表达、语句合法性检查、词性标注等。其实RNN原本的目的使用来处理序列数据。比如一系列的数据，呈现出规律性的特征时，那么就能使用循环神经网络，这种针对性恰好符合自然语言的一些特征，比如说我们能够通过联系上下文来确定“我是中国（ ）”来确认里面要填的是“人”字。或者是通过有规律的时序数学模型来预测接下来的数据是什么样的。在这些运用上面，RNN的效果都非常好。

RNNs包含输入单元(Input units)，输入集标记为{x0,x1,...,xt,xt+1,...}，而输出单元(Output units)的输出集则被标记为{y0,y1,...,yt,yt+1.,..}。RNNs还包含隐藏单元(Hidden units)，我们将其输出集标记为{s0,s1,...,st,st+1,...}，这些隐藏单元完成了最为主要的工作。

循环神经网络主要是将上一个状态的输出再放入下一个状态的输入中，这样就能够进行一个有序列性的预测了。理论上，RNNs能够对任何长度的序列数据进行处理。但是在实践中，为了降低复杂性往往假设当前的状态只与前面的几个状态相关。最后训练出的W是一个公用的参数矩阵，每一次输入输出都能使用这个参数W，而不是像卷积神经网络一样，每一层都会有一套训练出的参数和权重。但是如果记忆的窗口太长，例如一篇文章的首位呼应，那么RNN可能就没法做得很好，这会导致比较难以训练，这时候就会出现梯度消失或者梯度爆炸的问题，这时候为了解决这个情况的出现，就诞生了LSTM（长短期记忆网络），现在的循环神经网络大多都是由LSTM实现的。

![pic](/assets/images/2017-08-31-1_2.png)

LSTM的第一步就是决定什么信息应该被神经元遗忘。这是一个被称为“遗忘门层”的Sigmod层组成的。它输入 ht−1 和 xt ,然后在 Ct−1 的每个神经元状态输出0~1之间的数字。“1”表示“完全保留这个”，“0”表示“完全遗忘这个”。 
让我们回到尝试去根据之前的词语去预测下一个单词的语言模型。在这个问题中，神经元状态或许包括当前主语中的性别信息，所以可以使用正确的代词。当我们看到一个新的主语，我们会去遗忘之前的性别信息。 

![pic](/assets/images/2017-08-31-1_3.png)

下一步就是决定我们要在神经元细胞中保存什么信息，这包括两个部分。首先，一个被称为“遗忘门层”的Sigmod层决定我们要更新的数值。然后，一个tanh层生成一个新的候选数值， Ct˜ ,它会被增加到神经元状态中。在下一步中中，我们会组合这两步去生成一个更新状态值。

在那个语言模型例子中，我们想给神经元状态增加新的主语的性别，替换我们将要遗忘的旧的主语。

![pic](/assets/images/2017-08-31-1_4.png)

是时候去更新旧的神经元状态 Ct−1 到新的神经元状态 Ct 了。之前的步骤已经决定要做什么，下一步我们就去做。

我们给旧的状态乘以一个 ft ,遗忘掉我们之前决定要遗忘的信息，然后我们增加 it*Ct˜ 。这是新的候选值，是由我们想多大程度上更新每个状态的值来度量的。 

在语言模型中，就像上面描述的，这是我们实际上要丢弃之前主语的性别信息，增加新的主语的性别信息的地方。

![pic](/assets/images/2017-08-31-1_5.png)

最后，我们要决定要输出什么。这个输出是建立在我们的神经元状态的基础上的，但是有一个滤波器。首先，我们使用Sigmod层决定哪一部分的神经元状态需要被输出；然后我们让神经元状态经过tanh（让输出值变为-1~1之间）层并且乘上Sigmod门限的输出，我们只输出我们想要输出的。

对于那个语言模型的例子，当我们看到一个主语的时候，或许我们想输出相关动词的信息，因为动词是紧跟在主语之后的。例如，它或许要输出主语是单数还是复数的，然后我们就知道主语联结的动词的语态了。

接下来是一个算法的简单实现实例，我们将整个算法一步步分析，并且了解它是如何运行的，这里主要描述一个大概思路

首先我们需要两个csv的支持文件，两个文件一个是训练数据，一个是验证数据，里面存有二维平面上面的N个点，这N个点被分为三类。存在CSV中的数据格式为（x，y，类别）

加载所需要的library

{% highlight python %}
import numpy
import matplotlib.pyplot as plt
from pandas import read_csv
import math
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
%matplotlib inline
{% endhighlight %}

通过pandas读取一个csv文件，里面存有的是1940年到1960年乘坐国际航班的人数

{% highlight python %}
#通过library读取csv文件
dataframe = read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)
dataset = dataframe.values

# 将整型变为float
dataset = dataset.astype('float32')
print dataset

#将趋势打印出来
plt.plot(dataset)
plt.show()
{% endhighlight %}

![pic](/assets/images/2017-08-31-1_6.png)

创建一个函数，分别返回文件中的x和标签y。但是对于循环神经网络，我们的y就是下一个输入，比如说我们有一串数列[6，2，5，7，9]，那么如果6是输入，2就是输出；2为输入，5就是输出。在此处，我们就是做一个这样的工作。

{% highlight python %}
#通过读取的csv文件，返回两个值，一个是X，一个是对应的标签Y
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return numpy.array(dataX), numpy.array(dataY)
{% endhighlight %}

通过数学公式的变换将数据分布在0到1的区间内。

{% highlight python %}
#此处的MinMaxScaler是将数据分布在[0，1]的区间内
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

print dataset

#将数据分为两份，一份用来训练，一份用来做预测。
# split into train and test sets
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
{% endhighlight %}

其中的train是用作训练，testX并不会使用到训练里，testY没用在程序中用到。

{% highlight python %}
#创建测试数据以及训练数据
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)
print trainX,trainY
#使训练数据和测试数据符合输入格式
trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))
{% endhighlight %}

使用Sequential模型，代表所有的操作是一个线性的关系，一层结束后才开始一下一层。

{% highlight python %}
#调用keras直接创建模型
model = Sequential()
#使用RNN的长短时记忆模型，将数据输入
model.add(LSTM(32, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
#训练100次，每次喂入5个数据
model.fit(trainX, trainY, epochs=100, batch_size=5)
{% endhighlight %}

将trainX和testX放入训练好的模型中进行预测，所得的值赋给两个predict。

{% highlight python %}
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
print trainX.shape
{% endhighlight %}

将两个predict从0到1的区间反向转换回原来的人数

{% highlight python %}
trainPredict = scaler.inverse_transform(trainPredict)
#trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
#testY = scaler.inverse_transform([testY])
{% endhighlight %}

将最后结果打印出来，我们可以看到，红色的是真实数据，蓝色的是我们预测的走势，可以看出略有时间上的延迟，但是大致的图形走势是完美预测的。

{% highlight python %}
plt.plot(numpy.vstack((trainPredict,testPredict)))
#plt.plot(trainPredictPlot,'cyan')
#plt.plot(testPredictPlot,'r')
plt.plot(scaler.inverse_transform(dataset),'r')
plt.show()
{% endhighlight %}

![pic](/assets/images/2017-08-31-1_7.png)